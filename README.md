# NAS-PINN: Neural Architecture Search for Physics-Informed Neural Networks

## ğŸ¯ Project Overview

This repository implements **Neural Architecture Search (NAS)** for Physics-Informed Neural Networks (PINNs) applied to the **Burgers Equation** - a fundamental nonlinear PDE in fluid dynamics.

### Key Features
- âœ… **3 NAS Methods**: NSGA-II, NSGA-III, Bayesian Optimization
- âœ… **Automatic Architecture Discovery**: Optimizes network depth, width, and learning rate
- âœ… **Multi-Regime Benchmark**: Tests across 3 viscosity values (Î½ = 0.01, 0.04, 0.07)
- âœ… **Comprehensive Evaluation**: L2 error, MSE, RMSE, MAE, parameter count
- âœ… **Rich Visualizations**: Heatmaps, snapshots, error distributions, loss curves

---

## ğŸ“ Problem Formulation

### Burgers Equation
```
âˆ‚u/âˆ‚t + uÂ·âˆ‚u/âˆ‚x - (Î½/Ï€)Â·âˆ‚Â²u/âˆ‚xÂ² = 0
```

**Domain:**
- Spatial: x âˆˆ [-1, 1]
- Temporal: t âˆˆ [0, 1]

**Initial Condition:**
```
u(0, x) = -sin(Ï€x)
```

**Boundary Conditions:**
```
u(t, -1) = 0
u(t, +1) = 0
```

**Viscosity Values:**
- Î½ = 0.01 â†’ Highly advective (shock-like structures, most challenging)
- Î½ = 0.04 â†’ Moderate regime (balanced advection-diffusion)
- Î½ = 0.07 â†’ Diffusion-dominated (smooth solution, easier)

---

## ğŸ—ï¸ Architecture

### File Structure
```
NAS-PINNS1/
â”‚
â”œâ”€â”€ naspinn.py              # Core PINN implementation
â”œâ”€â”€ nsga2_search.py         # NSGA-II optimization
â”œâ”€â”€ nsga3_search.py         # NSGA-III optimization
â”œâ”€â”€ bayes_opt_search.py     # Bayesian optimization
â”œâ”€â”€ run_all.py              # Main execution script
â”œâ”€â”€ README.md               # This file
â”‚
â””â”€â”€ results/                # Generated results
    â”œâ”€â”€ nu_0.01/
    â”‚   â”œâ”€â”€ nsga2/
    â”‚   â”œâ”€â”€ nsga3/
    â”‚   â””â”€â”€ bayesian/
    â”œâ”€â”€ nu_0.04/
    â”œâ”€â”€ nu_0.07/
    â””â”€â”€ comparison.csv
```

### Core Components

#### 1. `naspinn.py`
- `ResidualBurgerPINN`: PINN class with optional residual connections and tanh activation
- `generate_data()`: Creates training data (collocation, boundary, initial points)
- `pde_loss()`: Computes PDE residual using automatic differentiation
- `train_pinn()`: Trains model using Adam optimizer (default 1200 epochs, lr=3e-4)
- Training progress is printed every 100 epochs in terminal
- `compute_mean_l2_error()`: Evaluates time-averaged relative L2 error
- Visualization functions for heatmaps, snapshots, comparisons

#### 2. `nsga2_search.py`
- Multi-objective optimization (minimize L2 error + parameters)
- Population: 10, Generations: 5 (fast mode)
- Search space: 4-8 hidden layers, 48-256 neurons/layer
- Also optimizes learning rate, residual toggle, and PDE loss weight factor

#### 3. `nsga3_search.py`
- Many-objective optimization (L2 error + parameters + training time)
- Population: 10, Generations: 5 (fast mode)
- Reference directions for Pareto front
- Additional learning rate optimization

#### 4. `bayes_opt_search.py`
- Gaussian Process-based optimization
- Default: 10 iterations, 2 initial random points
- In `run_all.py` fast preset: 8 iterations, 2 initial random points
- Optimizes: layers, neurons, learning rate

---

