Starting Adam + bi-level optimization...
[    0] PDE: 5.3608e-02  IC: 4.2733e-01  BC: 9.3734e-02
[ 2000] PDE: 3.4506e-01  IC: 1.0316e-04  BC: 2.1635e-05
[ 4000] PDE: 2.4933e-01  IC: 6.2057e-05  BC: 4.4361e-06
[ 6000] PDE: 2.1001e-01  IC: 5.3959e-05  BC: 1.6839e-06
[ 8000] PDE: 9.8820e-02  IC: 2.3195e-05  BC: 8.8166e-07
[10000] PDE: 1.1704e-02  IC: 7.4843e-06  BC: 9.3437e-07
[12000] PDE: 6.5346e-03  IC: 7.9362e-06  BC: 6.5134e-06
[14000] PDE: 5.6096e-03  IC: 3.1778e-05  BC: 1.2176e-05

L-BFGS refinement...

Discovered architecture (most probable ops & mask):
Layer 1: Sin , neurons ≈ 128
Layer 2: Tanh , neurons ≈ 128
Layer 3: Tanh , neurons ≈ 96
Layer 4: Tanh , neurons ≈ 128
Saved plot: results_plots/burgers_heatmap.png
Saved plot: results_plots/burgers_time_slices.png
Saved plot: results_plots/burgers_exact_vs_pred_time_slices.png
Relative L2 error (full grid): 5.3641e-03
Saved plot: results_plots/burgers_full_exact_vs_pred.png

----------------------------------------------------------------

Starting Adam + bi-level optimization...
[    0] PDE residual: 9.6314e+01   BC: 8.7650e-01
[ 2000] PDE residual: 2.6579e-03   BC: 2.1450e-05
[ 4000] PDE residual: 7.2430e-04   BC: 4.6431e-06
[ 6000] PDE residual: 8.0859e-04   BC: 4.8233e-06
[ 8000] PDE residual: 3.1626e-04   BC: 2.3032e-06
[10000] PDE residual: 1.0477e-03   BC: 9.5100e-06

L-BFGS refinement...

Discovered architecture (most probable ops & mask):
Layer 1: Sin , neurons ≈ 96
Layer 2: Sin , neurons ≈ 256
Layer 3: Linear/Identity , neurons ≈ 192

Relative L2 error (full grid): 6.5441e-05
Saved plot: results_plots/poisson_results.png

-------------------------------------------------------


|   iter    |  target   | n_layers  |    n1     |    n2     |    n3     |    n4     |    a1     |    a2     |    a3     |    a4     |    lr     |
-------------------------------------------------------------------------------------------------------------------------------------------------
BO eval 01 | widths=[184, 149, 128] acts=['tanh', 'tanh', 'sin'] lr=1.56e-03 | relL2=3.5878e-01
| 1         | -0.358778 | 3.3745401 | 184.11428 | 149.11903 | 127.78535 | 56.962982 | 0.1559945 | 0.0580836 | 0.8661761 | 0.6011150 | 0.0015621 |
BO eval 02 | widths=[187, 165, 66] acts=['tanh', 'tanh', 'sin'] lr=9.37e-04 | relL2=3.8305e-01
| 2         | -0.383050 | 3.0205844 | 187.18557 | 165.19082 | 65.974257 | 61.091994 | 0.1834045 | 0.3042422 | 0.5247564 | 0.4319450 | 0.0009368 |
BO eval 03 | widths=[183, 156, 134, 51] acts=['sin', 'sin', 'tanh', 'tanh'] lr=1.54e-03 | relL2=2.9837e-01
| 3         | -0.298372 | 3.9614923 | 183.49878 | 156.30628 | 134.17384 | 51.098049 | 0.8344659 | 0.7680948 | 0.4174409 | 0.2656772 | 0.0015426 |
BO eval 04 | widths=[39, 137, 68, 137] acts=['sin', 'sin', 'tanh', 'sin'] lr=1.15e-03 | relL2=4.3003e-01
| 4         | -0.430032 | 3.6764765 | 38.734159 | 136.96104 | 68.334813 | 137.47051 | 0.8797493 | 0.9542661 | 0.3687843 | 0.6574882 | 0.0011509 |
BO eval 05 | widths=[180, 163, 136, 51] acts=['sin', 'sin', 'tanh', 'tanh'] lr=1.63e-03 | relL2=2.9162e-01
| 5         | -0.291617 | 4.0       | 180.41622 | 162.72976 | 135.80771 | 51.087838 | 0.9880791 | 1.0       | 0.3130397 | 0.1343938 | 0.0016331 |
BO eval 06 | widths=[188, 161, 146, 37] acts=['sin', 'sin', 'tanh', 'tanh'] lr=1.45e-03 | relL2=3.1775e-01
| 6         | -0.317754 | 4.0       | 187.84915 | 160.88038 | 146.26386 | 37.316888 | 1.0       | 1.0       | 0.0       | 0.0       | 0.0014524 |
BO eval 07 | widths=[192, 165, 149, 60] acts=['sin', 'sin', 'tanh', 'tanh'] lr=5.00e-04 | relL2=4.2369e-01
| 7         | -0.423685 | 4.0       | 192.0     | 165.34015 | 149.41493 | 60.415534 | 1.0       | 1.0       | 0.0       | 0.4657127 | 0.0005    |
BO eval 08 | widths=[178, 160, 133, 39] acts=['sin', 'sin', 'tanh', 'tanh'] lr=2.00e-03 | relL2=2.6573e-01
| 8         | -0.265729 | 4.0       | 177.53123 | 159.72638 | 132.61338 | 39.252676 | 1.0       | 1.0       | 0.1606764 | 0.0       | 0.002     |
BO eval 09 | widths=[174, 160, 127] acts=['sin', 'sin', 'tanh'] lr=6.82e-04 | relL2=3.6806e-01
| 9         | -0.368055 | 3.4562783 | 173.94199 | 159.71518 | 127.23750 | 41.788566 | 0.5315197 | 0.9101602 | 0.4502609 | 0.5508187 | 0.0006820 |
BO eval 10 | widths=[181, 160, 136, 43] acts=['sin', 'sin', 'tanh', 'tanh'] lr=2.00e-03 | relL2=2.7136e-01
| 10        | -0.271358 | 4.0       | 181.09175 | 159.81032 | 136.28786 | 42.755798 | 1.0       | 0.9895148 | 0.1284682 | 0.0       | 0.002     |
=================================================================================================================================================

Best architecture from BO
hidden widths: [178, 160, 133, 39]
hidden acts  : ['sin', 'sin', 'tanh', 'tanh']
lr           : 2.0000e-03
BO rel L2    : 2.6573e-01
Saved checkpoint: results_plots1/bayes_checkpoint_last.pth
Final relative L2 error: 5.7080e-03

---------------------------------------------------------------------------------------

coder@coder-omerc-pinns-6679cf7456-gphvg:~/NAS-PINNS1$ python  NAS_PINNs_poisson_bayesian.py
|   iter    |  target   | n_layers  |    n1     |    n2     |    n3     |    n4     |    a1     |    a2     |    a3     |    a4     |    lr     |
-------------------------------------------------------------------------------------------------------------------------------------------------
BO eval 01 | widths=[245, 196, 166] acts=['tanh', 'tanh', 'sin'] lr=1.56e-03 | relL2=4.6539e-03
| 1         | -0.004653 | 2.7490802 | 244.96000 | 195.96664 | 166.09950 | 66.948175 | 0.1559945 | 0.0580836 | 0.8661761 | 0.6011150 | 0.0015621 |
BO eval 02 | widths=[249, 218] acts=['tanh', 'tanh'] lr=9.37e-04 | relL2=7.9013e-03
| 2         | -0.007901 | 2.0411689 | 249.25980 | 218.46715 | 79.563960 | 72.728792 | 0.1834045 | 0.3042422 | 0.5247564 | 0.4319450 | 0.0009368 |
BO eval 03 | widths=[244, 206, 175, 59] acts=['sin', 'sin', 'tanh', 'tanh'] lr=1.54e-03 | relL2=2.1374e-03
| 3         | -0.002137 | 3.9229846 | 244.09829 | 206.02880 | 175.04338 | 58.737269 | 0.8344659 | 0.7680948 | 0.4174409 | 0.2656772 | 0.0015426 |
BO eval 04 | widths=[239, 192, 170] acts=['tanh', 'tanh', 'tanh'] lr=7.86e-04 | relL2=5.5054e-03
| 4         | -0.005505 | 3.1342210 | 238.71967 | 191.70971 | 170.14994 | 54.238434 | 0.4902214 | 0.2138223 | 0.0141961 | 0.6799607 | 0.0007864 |
BO eval 05 | widths=[241, 208, 175, 60] acts=['sin', 'sin', 'tanh', 'tanh'] lr=1.50e-03 | relL2=1.1858e-02
| 5         | -0.011858 | 3.8499050 | 241.06161 | 208.39189 | 175.11962 | 59.975629 | 0.6116301 | 0.8205618 | 0.4045529 | 0.3886615 | 0.0014975 |
BO eval 06 | widths=[94, 46, 151] acts=['tanh', 'tanh', 'sin'] lr=8.71e-04 | relL2=2.0202e-03
| 6         | -0.002020 | 3.1179604 | 93.636303 | 45.546399 | 151.12631 | 200.83788 | 0.2500910 | 0.3222127 | 0.5670430 | 0.4165768 | 0.0008708 |
BO eval 07 | widths=[188, 101, 191] acts=['sin', 'tanh', 'sin'] lr=1.85e-03 | relL2=5.4084e-02
| 7         | -0.054084 | 3.4455902 | 187.87482 | 101.46821 | 191.25689 | 65.122584 | 0.8448653 | 0.4837527 | 0.6143838 | 0.2265684 | 0.0018456 |
BO eval 08 | widths=[256, 197, 178, 55] acts=['sin', 'sin', 'sin', 'tanh'] lr=1.88e-03 | relL2=1.2999e-03
| 8         | -0.001299 | 3.8820881 | 256.0     | 197.10292 | 178.14376 | 54.725354 | 1.0       | 0.5926114 | 0.6272800 | 0.1459973 | 0.0018843 |
BO eval 09 | widths=[163, 52, 141, 169] acts=['tanh', 'sin', 'sin', 'sin'] lr=1.32e-03 | relL2=1.5228e-03
| 9         | -0.001522 | 3.7134244 | 163.21788 | 52.391570 | 140.84167 | 168.89190 | 0.3374028 | 0.5962808 | 0.6624828 | 0.6760608 | 0.0013175 |
BO eval 10 | widths=[255, 206, 163, 50] acts=['sin', 'sin', 'tanh', 'tanh'] lr=5.00e-04 | relL2=2.9916e-03
| 10        | -0.002991 | 4.0       | 254.58134 | 206.27620 | 163.39133 | 50.342165 | 1.0       | 1.0       | 0.4329969 | 0.0       | 0.0005    |
=================================================================================================================================================

Best architecture from BO
hidden widths: [256, 197, 178, 55]
hidden acts  : ['sin', 'sin', 'sin', 'tanh']
lr           : 1.8843e-03
BO rel L2    : 1.2999e-03
Saved checkpoint: results_plots_poisson_bayes/bayes_poisson_checkpoint_last.pth
Final relative L2 error: 5.0662e-05